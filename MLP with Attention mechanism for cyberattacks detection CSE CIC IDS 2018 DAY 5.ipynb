{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\fer_u\\pycharmprojects\\cyberattacksattention\\venv\\lib\\site-packages (2.11.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.11.0 in c:\\users\\fer_u\\pycharmprojects\\cyberattacksattention\\venv\\lib\\site-packages (from tensorflow) (2.11.0)\n",
      "Requirement already satisfied: keras<2.12,>=2.11.0 in c:\\users\\fer_u\\pycharmprojects\\cyberattacksattention\\venv\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (2.11.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\fer_u\\pycharmprojects\\cyberattacksattention\\venv\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in c:\\users\\fer_u\\pycharmprojects\\cyberattacksattention\\venv\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (2.11.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\fer_u\\pycharmprojects\\cyberattacksattention\\venv\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (60.2.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\fer_u\\pycharmprojects\\cyberattacksattention\\venv\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\fer_u\\pycharmprojects\\cyberattacksattention\\venv\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\fer_u\\pycharmprojects\\cyberattacksattention\\venv\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (22.0)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in c:\\users\\fer_u\\pycharmprojects\\cyberattacksattention\\venv\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (3.19.6)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\fer_u\\pycharmprojects\\cyberattacksattention\\venv\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.51.1)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\fer_u\\pycharmprojects\\cyberattacksattention\\venv\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\fer_u\\pycharmprojects\\cyberattacksattention\\venv\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\fer_u\\pycharmprojects\\cyberattacksattention\\venv\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (4.4.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\fer_u\\pycharmprojects\\cyberattacksattention\\venv\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\fer_u\\pycharmprojects\\cyberattacksattention\\venv\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (3.7.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\fer_u\\pycharmprojects\\cyberattacksattention\\venv\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (14.0.6)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\fer_u\\pycharmprojects\\cyberattacksattention\\venv\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.23.5)\n",
      "Requirement already satisfied: tensorboard<2.12,>=2.11 in c:\\users\\fer_u\\pycharmprojects\\cyberattacksattention\\venv\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (2.11.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\fer_u\\pycharmprojects\\cyberattacksattention\\venv\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\fer_u\\pycharmprojects\\cyberattacksattention\\venv\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (22.12.6)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\fer_u\\pycharmprojects\\cyberattacksattention\\venv\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\fer_u\\pycharmprojects\\cyberattacksattention\\venv\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (0.28.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\fer_u\\pycharmprojects\\cyberattacksattention\\venv\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.11.0->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\fer_u\\pycharmprojects\\cyberattacksattention\\venv\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\fer_u\\pycharmprojects\\cyberattacksattention\\venv\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\fer_u\\pycharmprojects\\cyberattacksattention\\venv\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\fer_u\\pycharmprojects\\cyberattacksattention\\venv\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.28.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\fer_u\\pycharmprojects\\cyberattacksattention\\venv\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\fer_u\\pycharmprojects\\cyberattacksattention\\venv\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\fer_u\\pycharmprojects\\cyberattacksattention\\venv\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.15.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\fer_u\\pycharmprojects\\cyberattacksattention\\venv\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\fer_u\\pycharmprojects\\cyberattacksattention\\venv\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (5.2.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\fer_u\\pycharmprojects\\cyberattacksattention\\venv\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\fer_u\\pycharmprojects\\cyberattacksattention\\venv\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\fer_u\\pycharmprojects\\cyberattacksattention\\venv\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (5.1.0)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\fer_u\\pycharmprojects\\cyberattacksattention\\venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\fer_u\\pycharmprojects\\cyberattacksattention\\venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\fer_u\\pycharmprojects\\cyberattacksattention\\venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\fer_u\\pycharmprojects\\cyberattacksattention\\venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (1.26.13)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\fer_u\\pycharmprojects\\cyberattacksattention\\venv\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\fer_u\\pycharmprojects\\cyberattacksattention\\venv\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (3.11.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\fer_u\\pycharmprojects\\cyberattacksattention\\venv\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\fer_u\\pycharmprojects\\cyberattacksattention\\venv\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (3.2.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.3.1; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\Fer_U\\PycharmProjects\\CyberattacksAttention\\venv\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\fer_u\\pycharmprojects\\cyberattacksattention\\venv\\lib\\site-packages (1.5.2)\n",
      "Requirement already satisfied: numpy>=1.20.3 in c:\\users\\fer_u\\pycharmprojects\\cyberattacksattention\\venv\\lib\\site-packages (from pandas) (1.23.5)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\fer_u\\pycharmprojects\\cyberattacksattention\\venv\\lib\\site-packages (from pandas) (2022.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\fer_u\\pycharmprojects\\cyberattacksattention\\venv\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\fer_u\\pycharmprojects\\cyberattacksattention\\venv\\lib\\site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.3.1; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\Fer_U\\PycharmProjects\\CyberattacksAttention\\venv\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: neural_structured_learning in c:\\users\\fer_u\\pycharmprojects\\cyberattacksattention\\venv\\lib\\site-packages (1.4.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\fer_u\\pycharmprojects\\cyberattacksattention\\venv\\lib\\site-packages (from neural_structured_learning) (1.9.3)\n",
      "Requirement already satisfied: absl-py in c:\\users\\fer_u\\pycharmprojects\\cyberattacksattention\\venv\\lib\\site-packages (from neural_structured_learning) (1.3.0)\n",
      "Requirement already satisfied: six in c:\\users\\fer_u\\pycharmprojects\\cyberattacksattention\\venv\\lib\\site-packages (from neural_structured_learning) (1.16.0)\n",
      "Requirement already satisfied: attrs in c:\\users\\fer_u\\pycharmprojects\\cyberattacksattention\\venv\\lib\\site-packages (from neural_structured_learning) (22.1.0)\n",
      "Requirement already satisfied: numpy<1.26.0,>=1.18.5 in c:\\users\\fer_u\\pycharmprojects\\cyberattacksattention\\venv\\lib\\site-packages (from scipy->neural_structured_learning) (1.23.5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.3.1; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\Fer_U\\PycharmProjects\\CyberattacksAttention\\venv\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install neural_structured_learning"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit_learn in c:\\users\\fer_u\\pycharmprojects\\cyberattacksattention\\venv\\lib\\site-packages (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\fer_u\\pycharmprojects\\cyberattacksattention\\venv\\lib\\site-packages (from scikit_learn) (3.1.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\fer_u\\pycharmprojects\\cyberattacksattention\\venv\\lib\\site-packages (from scikit_learn) (1.9.3)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\fer_u\\pycharmprojects\\cyberattacksattention\\venv\\lib\\site-packages (from scikit_learn) (1.23.5)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\fer_u\\pycharmprojects\\cyberattacksattention\\venv\\lib\\site-packages (from scikit_learn) (1.2.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.3.1; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\Fer_U\\PycharmProjects\\CyberattacksAttention\\venv\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit_learn"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "executionInfo": {
     "elapsed": 4460,
     "status": "ok",
     "timestamp": 1670604423667,
     "user": {
      "displayName": "Fernando José Rendón Segador",
      "userId": "09288482551460164544"
     },
     "user_tz": -60
    },
    "id": "bTL3Ufo0t487",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import neural_structured_learning as nsl\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "executionInfo": {
     "elapsed": 1214,
     "status": "ok",
     "timestamp": 1670604426852,
     "user": {
      "displayName": "Fernando José Rendón Segador",
      "userId": "09288482551460164544"
     },
     "user_tz": -60
    },
    "id": "xdB9GixktNz0",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('CSE_CIC_IDS_2018/02-21-2018.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1670604426856,
     "user": {
      "displayName": "Fernando José Rendón Segador",
      "userId": "09288482551460164544"
     },
     "user_tz": -60
    },
    "id": "856UWFEmyUms",
    "outputId": "a5a2bcaf-4a37-454e-eb77-2ffe6b9b956f",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   Dst Port  Protocol            Timestamp  Flow Duration  Tot Fwd Pkts  \\\n0        80         6  21/02/2018 08:33:25          37953             5   \n1       500        17  21/02/2018 08:33:06      117573474             3   \n2       500        17  21/02/2018 08:33:06      117573474             3   \n3       500        17  21/02/2018 08:33:11       99743998             5   \n4       500        17  21/02/2018 08:33:11       99743999             5   \n\n   Tot Bwd Pkts  TotLen Fwd Pkts  TotLen Bwd Pkts  Fwd Pkt Len Max  \\\n0             3              135              127              135   \n1             0             1500                0              500   \n2             0             1500                0              500   \n3             0             2500                0              500   \n4             0             2500                0              500   \n\n   Fwd Pkt Len Min  Fwd Pkt Len Mean  Fwd Pkt Len Std  Bwd Pkt Len Max  \\\n0                0              27.0        60.373835              127   \n1              500             500.0         0.000000                0   \n2              500             500.0         0.000000                0   \n3              500             500.0         0.000000                0   \n4              500             500.0         0.000000                0   \n\n   Bwd Pkt Len Min  Bwd Pkt Len Mean  Bwd Pkt Len Std  Flow Byts/s  \\\n0                0         42.333333        73.323484  6903.275103   \n1                0          0.000000         0.000000    12.757980   \n2                0          0.000000         0.000000    12.757980   \n3                0          0.000000         0.000000    25.064165   \n4                0          0.000000         0.000000    25.064165   \n\n   Flow Pkts/s  Flow IAT Mean  Flow IAT Std  Flow IAT Max  Flow IAT Min  \\\n0   210.787026   5.421857e+03  5.403580e+03         12099            23   \n1     0.025516   5.880000e+07  2.380000e+07      75600000      42000000   \n2     0.025516   5.880000e+07  2.380000e+07      75600000      42000000   \n3     0.050128   2.490000e+07  3.400000e+07      75600000       4000290   \n4     0.050128   2.490000e+07  3.400000e+07      75600000       4000286   \n\n   Fwd IAT Tot  Fwd IAT Mean   Fwd IAT Std  Fwd IAT Max  Fwd IAT Min  \\\n0        37953       9488.25  3.245485e+03        12382         6013   \n1    118000000   58800000.00  2.380000e+07     75600000     42000000   \n2    118000000   58800000.00  2.380000e+07     75600000     42000000   \n3     99700000   24900000.00  3.400000e+07     75600000      4000290   \n4     99700000   24900000.00  3.400000e+07     75600000      4000286   \n\n   Bwd IAT Tot  Bwd IAT Mean  Bwd IAT Std  Bwd IAT Max  Bwd IAT Min  \\\n0        19960        9980.0  13546.75171        19559          401   \n1            0           0.0      0.00000            0            0   \n2            0           0.0      0.00000            0            0   \n3            0           0.0      0.00000            0            0   \n4            0           0.0      0.00000            0            0   \n\n   Fwd PSH Flags  Bwd PSH Flags  Fwd URG Flags  Bwd URG Flags  Fwd Header Len  \\\n0              0              0              0              0             168   \n1              0              0              0              0              24   \n2              0              0              0              0              24   \n3              0              0              0              0              40   \n4              0              0              0              0              40   \n\n   Bwd Header Len  Fwd Pkts/s  Bwd Pkts/s  Pkt Len Min  Pkt Len Max  \\\n0             104  131.741891   79.045135            0          135   \n1               0    0.025516    0.000000          500          500   \n2               0    0.025516    0.000000          500          500   \n3               0    0.050128    0.000000          500          500   \n4               0    0.050128    0.000000          500          500   \n\n   Pkt Len Mean  Pkt Len Std  Pkt Len Var  FIN Flag Cnt  SYN Flag Cnt  \\\n0     29.111111    57.800183  3340.861111             0             0   \n1    500.000000     0.000000     0.000000             0             0   \n2    500.000000     0.000000     0.000000             0             0   \n3    500.000000     0.000000     0.000000             0             0   \n4    500.000000     0.000000     0.000000             0             0   \n\n   RST Flag Cnt  PSH Flag Cnt  ACK Flag Cnt  URG Flag Cnt  CWE Flag Count  \\\n0             0             1             0             0               0   \n1             0             0             0             0               0   \n2             0             0             0             0               0   \n3             0             0             0             0               0   \n4             0             0             0             0               0   \n\n   ECE Flag Cnt  Down/Up Ratio  Pkt Size Avg  Fwd Seg Size Avg  \\\n0             0              0     32.750000              27.0   \n1             0              0    666.666667             500.0   \n2             0              0    666.666667             500.0   \n3             0              0    600.000000             500.0   \n4             0              0    600.000000             500.0   \n\n   Bwd Seg Size Avg  Fwd Byts/b Avg  Fwd Pkts/b Avg  Fwd Blk Rate Avg  \\\n0         42.333333               0               0                 0   \n1          0.000000               0               0                 0   \n2          0.000000               0               0                 0   \n3          0.000000               0               0                 0   \n4          0.000000               0               0                 0   \n\n   Bwd Byts/b Avg  Bwd Pkts/b Avg  Bwd Blk Rate Avg  Subflow Fwd Pkts  \\\n0               0               0                 0                 5   \n1               0               0                 0                 3   \n2               0               0                 0                 3   \n3               0               0                 0                 5   \n4               0               0                 0                 5   \n\n   Subflow Fwd Byts  Subflow Bwd Pkts  Subflow Bwd Byts  Init Fwd Win Byts  \\\n0               135                 3               127              29200   \n1              1500                 0                 0                 -1   \n2              1500                 0                 0                 -1   \n3              2500                 0                 0                 -1   \n4              2500                 0                 0                 -1   \n\n   Init Bwd Win Byts  Fwd Act Data Pkts  Fwd Seg Size Min  Active Mean  \\\n0                219                  1                32          0.0   \n1                 -1                  2                 8          0.0   \n2                 -1                  2                 8          0.0   \n3                 -1                  4                 8    4000290.0   \n4                 -1                  4                 8    4000286.0   \n\n   Active Std  Active Max  Active Min   Idle Mean    Idle Std  Idle Max  \\\n0         0.0           0           0         0.0         0.0         0   \n1         0.0           0           0  58800000.0  23800000.0  75600000   \n2         0.0           0           0  58800000.0  23800000.0  75600000   \n3         0.0     4000290     4000290  31900000.0  37900000.0  75600000   \n4         0.0     4000286     4000286  31900000.0  37900000.0  75600000   \n\n   Idle Min   Label  \n0         0  Benign  \n1  42000000  Benign  \n2  42000000  Benign  \n3   7200397  Benign  \n4   7200399  Benign  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Dst Port</th>\n      <th>Protocol</th>\n      <th>Timestamp</th>\n      <th>Flow Duration</th>\n      <th>Tot Fwd Pkts</th>\n      <th>Tot Bwd Pkts</th>\n      <th>TotLen Fwd Pkts</th>\n      <th>TotLen Bwd Pkts</th>\n      <th>Fwd Pkt Len Max</th>\n      <th>Fwd Pkt Len Min</th>\n      <th>Fwd Pkt Len Mean</th>\n      <th>Fwd Pkt Len Std</th>\n      <th>Bwd Pkt Len Max</th>\n      <th>Bwd Pkt Len Min</th>\n      <th>Bwd Pkt Len Mean</th>\n      <th>Bwd Pkt Len Std</th>\n      <th>Flow Byts/s</th>\n      <th>Flow Pkts/s</th>\n      <th>Flow IAT Mean</th>\n      <th>Flow IAT Std</th>\n      <th>Flow IAT Max</th>\n      <th>Flow IAT Min</th>\n      <th>Fwd IAT Tot</th>\n      <th>Fwd IAT Mean</th>\n      <th>Fwd IAT Std</th>\n      <th>Fwd IAT Max</th>\n      <th>Fwd IAT Min</th>\n      <th>Bwd IAT Tot</th>\n      <th>Bwd IAT Mean</th>\n      <th>Bwd IAT Std</th>\n      <th>Bwd IAT Max</th>\n      <th>Bwd IAT Min</th>\n      <th>Fwd PSH Flags</th>\n      <th>Bwd PSH Flags</th>\n      <th>Fwd URG Flags</th>\n      <th>Bwd URG Flags</th>\n      <th>Fwd Header Len</th>\n      <th>Bwd Header Len</th>\n      <th>Fwd Pkts/s</th>\n      <th>Bwd Pkts/s</th>\n      <th>Pkt Len Min</th>\n      <th>Pkt Len Max</th>\n      <th>Pkt Len Mean</th>\n      <th>Pkt Len Std</th>\n      <th>Pkt Len Var</th>\n      <th>FIN Flag Cnt</th>\n      <th>SYN Flag Cnt</th>\n      <th>RST Flag Cnt</th>\n      <th>PSH Flag Cnt</th>\n      <th>ACK Flag Cnt</th>\n      <th>URG Flag Cnt</th>\n      <th>CWE Flag Count</th>\n      <th>ECE Flag Cnt</th>\n      <th>Down/Up Ratio</th>\n      <th>Pkt Size Avg</th>\n      <th>Fwd Seg Size Avg</th>\n      <th>Bwd Seg Size Avg</th>\n      <th>Fwd Byts/b Avg</th>\n      <th>Fwd Pkts/b Avg</th>\n      <th>Fwd Blk Rate Avg</th>\n      <th>Bwd Byts/b Avg</th>\n      <th>Bwd Pkts/b Avg</th>\n      <th>Bwd Blk Rate Avg</th>\n      <th>Subflow Fwd Pkts</th>\n      <th>Subflow Fwd Byts</th>\n      <th>Subflow Bwd Pkts</th>\n      <th>Subflow Bwd Byts</th>\n      <th>Init Fwd Win Byts</th>\n      <th>Init Bwd Win Byts</th>\n      <th>Fwd Act Data Pkts</th>\n      <th>Fwd Seg Size Min</th>\n      <th>Active Mean</th>\n      <th>Active Std</th>\n      <th>Active Max</th>\n      <th>Active Min</th>\n      <th>Idle Mean</th>\n      <th>Idle Std</th>\n      <th>Idle Max</th>\n      <th>Idle Min</th>\n      <th>Label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>80</td>\n      <td>6</td>\n      <td>21/02/2018 08:33:25</td>\n      <td>37953</td>\n      <td>5</td>\n      <td>3</td>\n      <td>135</td>\n      <td>127</td>\n      <td>135</td>\n      <td>0</td>\n      <td>27.0</td>\n      <td>60.373835</td>\n      <td>127</td>\n      <td>0</td>\n      <td>42.333333</td>\n      <td>73.323484</td>\n      <td>6903.275103</td>\n      <td>210.787026</td>\n      <td>5.421857e+03</td>\n      <td>5.403580e+03</td>\n      <td>12099</td>\n      <td>23</td>\n      <td>37953</td>\n      <td>9488.25</td>\n      <td>3.245485e+03</td>\n      <td>12382</td>\n      <td>6013</td>\n      <td>19960</td>\n      <td>9980.0</td>\n      <td>13546.75171</td>\n      <td>19559</td>\n      <td>401</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>168</td>\n      <td>104</td>\n      <td>131.741891</td>\n      <td>79.045135</td>\n      <td>0</td>\n      <td>135</td>\n      <td>29.111111</td>\n      <td>57.800183</td>\n      <td>3340.861111</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>32.750000</td>\n      <td>27.0</td>\n      <td>42.333333</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>5</td>\n      <td>135</td>\n      <td>3</td>\n      <td>127</td>\n      <td>29200</td>\n      <td>219</td>\n      <td>1</td>\n      <td>32</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Benign</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>500</td>\n      <td>17</td>\n      <td>21/02/2018 08:33:06</td>\n      <td>117573474</td>\n      <td>3</td>\n      <td>0</td>\n      <td>1500</td>\n      <td>0</td>\n      <td>500</td>\n      <td>500</td>\n      <td>500.0</td>\n      <td>0.000000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>12.757980</td>\n      <td>0.025516</td>\n      <td>5.880000e+07</td>\n      <td>2.380000e+07</td>\n      <td>75600000</td>\n      <td>42000000</td>\n      <td>118000000</td>\n      <td>58800000.00</td>\n      <td>2.380000e+07</td>\n      <td>75600000</td>\n      <td>42000000</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.00000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>24</td>\n      <td>0</td>\n      <td>0.025516</td>\n      <td>0.000000</td>\n      <td>500</td>\n      <td>500</td>\n      <td>500.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>666.666667</td>\n      <td>500.0</td>\n      <td>0.000000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>1500</td>\n      <td>0</td>\n      <td>0</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>2</td>\n      <td>8</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>58800000.0</td>\n      <td>23800000.0</td>\n      <td>75600000</td>\n      <td>42000000</td>\n      <td>Benign</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>500</td>\n      <td>17</td>\n      <td>21/02/2018 08:33:06</td>\n      <td>117573474</td>\n      <td>3</td>\n      <td>0</td>\n      <td>1500</td>\n      <td>0</td>\n      <td>500</td>\n      <td>500</td>\n      <td>500.0</td>\n      <td>0.000000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>12.757980</td>\n      <td>0.025516</td>\n      <td>5.880000e+07</td>\n      <td>2.380000e+07</td>\n      <td>75600000</td>\n      <td>42000000</td>\n      <td>118000000</td>\n      <td>58800000.00</td>\n      <td>2.380000e+07</td>\n      <td>75600000</td>\n      <td>42000000</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.00000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>24</td>\n      <td>0</td>\n      <td>0.025516</td>\n      <td>0.000000</td>\n      <td>500</td>\n      <td>500</td>\n      <td>500.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>666.666667</td>\n      <td>500.0</td>\n      <td>0.000000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>1500</td>\n      <td>0</td>\n      <td>0</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>2</td>\n      <td>8</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>58800000.0</td>\n      <td>23800000.0</td>\n      <td>75600000</td>\n      <td>42000000</td>\n      <td>Benign</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>500</td>\n      <td>17</td>\n      <td>21/02/2018 08:33:11</td>\n      <td>99743998</td>\n      <td>5</td>\n      <td>0</td>\n      <td>2500</td>\n      <td>0</td>\n      <td>500</td>\n      <td>500</td>\n      <td>500.0</td>\n      <td>0.000000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>25.064165</td>\n      <td>0.050128</td>\n      <td>2.490000e+07</td>\n      <td>3.400000e+07</td>\n      <td>75600000</td>\n      <td>4000290</td>\n      <td>99700000</td>\n      <td>24900000.00</td>\n      <td>3.400000e+07</td>\n      <td>75600000</td>\n      <td>4000290</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.00000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>40</td>\n      <td>0</td>\n      <td>0.050128</td>\n      <td>0.000000</td>\n      <td>500</td>\n      <td>500</td>\n      <td>500.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>600.000000</td>\n      <td>500.0</td>\n      <td>0.000000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>5</td>\n      <td>2500</td>\n      <td>0</td>\n      <td>0</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>4</td>\n      <td>8</td>\n      <td>4000290.0</td>\n      <td>0.0</td>\n      <td>4000290</td>\n      <td>4000290</td>\n      <td>31900000.0</td>\n      <td>37900000.0</td>\n      <td>75600000</td>\n      <td>7200397</td>\n      <td>Benign</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>500</td>\n      <td>17</td>\n      <td>21/02/2018 08:33:11</td>\n      <td>99743999</td>\n      <td>5</td>\n      <td>0</td>\n      <td>2500</td>\n      <td>0</td>\n      <td>500</td>\n      <td>500</td>\n      <td>500.0</td>\n      <td>0.000000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>25.064165</td>\n      <td>0.050128</td>\n      <td>2.490000e+07</td>\n      <td>3.400000e+07</td>\n      <td>75600000</td>\n      <td>4000286</td>\n      <td>99700000</td>\n      <td>24900000.00</td>\n      <td>3.400000e+07</td>\n      <td>75600000</td>\n      <td>4000286</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.00000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>40</td>\n      <td>0</td>\n      <td>0.050128</td>\n      <td>0.000000</td>\n      <td>500</td>\n      <td>500</td>\n      <td>500.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>600.000000</td>\n      <td>500.0</td>\n      <td>0.000000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>5</td>\n      <td>2500</td>\n      <td>0</td>\n      <td>0</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>4</td>\n      <td>8</td>\n      <td>4000286.0</td>\n      <td>0.0</td>\n      <td>4000286</td>\n      <td>4000286</td>\n      <td>31900000.0</td>\n      <td>37900000.0</td>\n      <td>75600000</td>\n      <td>7200399</td>\n      <td>Benign</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1670604426856,
     "user": {
      "displayName": "Fernando José Rendón Segador",
      "userId": "09288482551460164544"
     },
     "user_tz": -60
    },
    "id": "mkez4dRDyZ4L",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "df = df.replace([np.inf, -np.inf], np.nan)\n",
    "df = df.dropna()\n",
    "df = df.reset_index(drop=True)\n",
    "df = df.drop(['Timestamp'], axis=1)\n",
    "\n",
    "features = len(df.columns) - 1\n",
    "\n",
    "df['Label'] = label_encoder.fit_transform(df['Label'])\n",
    "classes = df['Label'].nunique()\n",
    "df = df.astype(float)\n",
    "df = df.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 488
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1670604426857,
     "user": {
      "displayName": "Fernando José Rendón Segador",
      "userId": "09288482551460164544"
     },
     "user_tz": -60
    },
    "id": "6wz-53mHnm7p",
    "outputId": "fe64ae3c-8710-4fbe-fc93-ff39924faffd",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "         Dst Port  Protocol  Flow Duration  Tot Fwd Pkts  Tot Bwd Pkts  \\\n0              80         6          37953             5             3   \n1             500        17      117573474             3             0   \n2             500        17      117573474             3             0   \n3             500        17       99743998             5             0   \n4             500        17       99743999             5             0   \n...           ...       ...            ...           ...           ...   \n1048570     55484         6           1252             5             2   \n1048571     57624         6          19055             5             2   \n1048572     57623         6          36677             5             2   \n1048573     57625         6           1849             5             2   \n1048574     58120         6          20580             5             2   \n\n         TotLen Fwd Pkts  TotLen Bwd Pkts  Fwd Pkt Len Max  Fwd Pkt Len Min  \\\n0                    135              127              135                0   \n1                   1500                0              500              500   \n2                   1500                0              500              500   \n3                   2500                0              500              500   \n4                   2500                0              500              500   \n...                  ...              ...              ...              ...   \n1048570              935              274              935                0   \n1048571              935              341              935                0   \n1048572              935              341              935                0   \n1048573              935              341              935                0   \n1048574              935              299              935                0   \n\n         Fwd Pkt Len Mean  Fwd Pkt Len Std  Bwd Pkt Len Max  Bwd Pkt Len Min  \\\n0                      27               60              127                0   \n1                     500                0                0                0   \n2                     500                0                0                0   \n3                     500                0                0                0   \n4                     500                0                0                0   \n...                   ...              ...              ...              ...   \n1048570               187              418              274                0   \n1048571               187              418              341                0   \n1048572               187              418              341                0   \n1048573               187              418              341                0   \n1048574               187              418              299                0   \n\n         Bwd Pkt Len Mean  Bwd Pkt Len Std  Flow Byts/s  Flow Pkts/s  \\\n0                      42               73         6903          210   \n1                       0                0           12            0   \n2                       0                0           12            0   \n3                       0                0           25            0   \n4                       0                0           25            0   \n...                   ...              ...          ...          ...   \n1048570               137              193       965654         5591   \n1048571               170              241        66964          367   \n1048572               170              241        34790          190   \n1048573               170              241       690102         3785   \n1048574               149              211        59961          340   \n\n         Flow IAT Mean  Flow IAT Std  Flow IAT Max  Flow IAT Min  Fwd IAT Tot  \\\n0                 5421          5403         12099            23        37953   \n1             58800000      23800000      75600000      42000000    118000000   \n2             58800000      23800000      75600000      42000000    118000000   \n3             24900000      34000000      75600000       4000290     99700000   \n4             24900000      34000000      75600000       4000286     99700000   \n...                ...           ...           ...           ...          ...   \n1048570            208           248           628             7         1252   \n1048571           3175          7422         18322             3        19055   \n1048572           6112         14317         35332             4        36677   \n1048573            308           381           895             2         1849   \n1048574           3430          8143         20052             6        20580   \n\n         Fwd IAT Mean  Fwd IAT Std  Fwd IAT Max  Fwd IAT Min  Bwd IAT Tot  \\\n0                9488         3245        12382         6013        19960   \n1            58800000     23800000     75600000     42000000            0   \n2            58800000     23800000     75600000     42000000            0   \n3            24900000     34000000     75600000      4000290            0   \n4            24900000     34000000     75600000      4000286            0   \n...               ...          ...          ...          ...          ...   \n1048570           313          455          978            7          628   \n1048571          4763         9221        18593            3        18322   \n1048572          9169        17875        35978            7        35332   \n1048573           462          560         1171            2          895   \n1048574          5145        10147        20365            6        20052   \n\n         Bwd IAT Mean  Bwd IAT Std  Bwd IAT Max  Bwd IAT Min  Fwd PSH Flags  \\\n0                9980        13546        19559          401              0   \n1                   0            0            0            0              0   \n2                   0            0            0            0              0   \n3                   0            0            0            0              0   \n4                   0            0            0            0              0   \n...               ...          ...          ...          ...            ...   \n1048570           628            0          628          628              0   \n1048571         18322            0        18322        18322              0   \n1048572         35332            0        35332        35332              0   \n1048573           895            0          895          895              0   \n1048574         20052            0        20052        20052              0   \n\n         Bwd PSH Flags  Fwd URG Flags  Bwd URG Flags  Fwd Header Len  \\\n0                    0              0              0             168   \n1                    0              0              0              24   \n2                    0              0              0              24   \n3                    0              0              0              40   \n4                    0              0              0              40   \n...                ...            ...            ...             ...   \n1048570              0              0              0             124   \n1048571              0              0              0             124   \n1048572              0              0              0             124   \n1048573              0              0              0             124   \n1048574              0              0              0             124   \n\n         Bwd Header Len  Fwd Pkts/s  Bwd Pkts/s  Pkt Len Min  Pkt Len Max  \\\n0                   104         131          79            0          135   \n1                     0           0           0          500          500   \n2                     0           0           0          500          500   \n3                     0           0           0          500          500   \n4                     0           0           0          500          500   \n...                 ...         ...         ...          ...          ...   \n1048570              40        3993        1597            0          935   \n1048571              40         262         104            0          935   \n1048572              40         136          54            0          935   \n1048573              40        2704        1081            0          935   \n1048574              40         242          97            0          935   \n\n         Pkt Len Mean  Pkt Len Std  Pkt Len Var  FIN Flag Cnt  SYN Flag Cnt  \\\n0                  29           57         3340             0             0   \n1                 500            0            0             0             0   \n2                 500            0            0             0             0   \n3                 500            0            0             0             0   \n4                 500            0            0             0             0   \n...               ...          ...          ...           ...           ...   \n1048570           151          330       109512             0             0   \n1048571           159          335       112426             0             0   \n1048572           159          335       112426             0             0   \n1048573           159          335       112426             0             0   \n1048574           154          332       110468             0             0   \n\n         RST Flag Cnt  PSH Flag Cnt  ACK Flag Cnt  URG Flag Cnt  \\\n0                   0             1             0             0   \n1                   0             0             0             0   \n2                   0             0             0             0   \n3                   0             0             0             0   \n4                   0             0             0             0   \n...               ...           ...           ...           ...   \n1048570             1             1             0             0   \n1048571             1             1             0             0   \n1048572             1             1             0             0   \n1048573             1             1             0             0   \n1048574             1             1             0             0   \n\n         CWE Flag Count  ECE Flag Cnt  Down/Up Ratio  Pkt Size Avg  \\\n0                     0             0              0            32   \n1                     0             0              0           666   \n2                     0             0              0           666   \n3                     0             0              0           600   \n4                     0             0              0           600   \n...                 ...           ...            ...           ...   \n1048570               0             1              0           172   \n1048571               0             1              0           182   \n1048572               0             1              0           182   \n1048573               0             1              0           182   \n1048574               0             1              0           176   \n\n         Fwd Seg Size Avg  Bwd Seg Size Avg  Fwd Byts/b Avg  Fwd Pkts/b Avg  \\\n0                      27                42               0               0   \n1                     500                 0               0               0   \n2                     500                 0               0               0   \n3                     500                 0               0               0   \n4                     500                 0               0               0   \n...                   ...               ...             ...             ...   \n1048570               187               137               0               0   \n1048571               187               170               0               0   \n1048572               187               170               0               0   \n1048573               187               170               0               0   \n1048574               187               149               0               0   \n\n         Fwd Blk Rate Avg  Bwd Byts/b Avg  Bwd Pkts/b Avg  Bwd Blk Rate Avg  \\\n0                       0               0               0                 0   \n1                       0               0               0                 0   \n2                       0               0               0                 0   \n3                       0               0               0                 0   \n4                       0               0               0                 0   \n...                   ...             ...             ...               ...   \n1048570                 0               0               0                 0   \n1048571                 0               0               0                 0   \n1048572                 0               0               0                 0   \n1048573                 0               0               0                 0   \n1048574                 0               0               0                 0   \n\n         Subflow Fwd Pkts  Subflow Fwd Byts  Subflow Bwd Pkts  \\\n0                       5               135                 3   \n1                       3              1500                 0   \n2                       3              1500                 0   \n3                       5              2500                 0   \n4                       5              2500                 0   \n...                   ...               ...               ...   \n1048570                 5               935                 2   \n1048571                 5               935                 2   \n1048572                 5               935                 2   \n1048573                 5               935                 2   \n1048574                 5               935                 2   \n\n         Subflow Bwd Byts  Init Fwd Win Byts  Init Bwd Win Byts  \\\n0                     127              29200                219   \n1                       0                 -1                 -1   \n2                       0                 -1                 -1   \n3                       0                 -1                 -1   \n4                       0                 -1                 -1   \n...                   ...                ...                ...   \n1048570               274              65535              32768   \n1048571               341              65535              32768   \n1048572               341              65535              32768   \n1048573               341              65535              32768   \n1048574               299              65535              32768   \n\n         Fwd Act Data Pkts  Fwd Seg Size Min  Active Mean  Active Std  \\\n0                        1                32            0           0   \n1                        2                 8            0           0   \n2                        2                 8            0           0   \n3                        4                 8      4000290           0   \n4                        4                 8      4000286           0   \n...                    ...               ...          ...         ...   \n1048570                  1                20            0           0   \n1048571                  1                20            0           0   \n1048572                  1                20            0           0   \n1048573                  1                20            0           0   \n1048574                  1                20            0           0   \n\n         Active Max  Active Min  Idle Mean  Idle Std  Idle Max  Idle Min  \\\n0                 0           0          0         0         0         0   \n1                 0           0   58800000  23800000  75600000  42000000   \n2                 0           0   58800000  23800000  75600000  42000000   \n3           4000290     4000290   31900000  37900000  75600000   7200397   \n4           4000286     4000286   31900000  37900000  75600000   7200399   \n...             ...         ...        ...       ...       ...       ...   \n1048570           0           0          0         0         0         0   \n1048571           0           0          0         0         0         0   \n1048572           0           0          0         0         0         0   \n1048573           0           0          0         0         0         0   \n1048574           0           0          0         0         0         0   \n\n         Label  \n0            0  \n1            0  \n2            0  \n3            0  \n4            0  \n...        ...  \n1048570      0  \n1048571      0  \n1048572      0  \n1048573      0  \n1048574      0  \n\n[1048575 rows x 79 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Dst Port</th>\n      <th>Protocol</th>\n      <th>Flow Duration</th>\n      <th>Tot Fwd Pkts</th>\n      <th>Tot Bwd Pkts</th>\n      <th>TotLen Fwd Pkts</th>\n      <th>TotLen Bwd Pkts</th>\n      <th>Fwd Pkt Len Max</th>\n      <th>Fwd Pkt Len Min</th>\n      <th>Fwd Pkt Len Mean</th>\n      <th>Fwd Pkt Len Std</th>\n      <th>Bwd Pkt Len Max</th>\n      <th>Bwd Pkt Len Min</th>\n      <th>Bwd Pkt Len Mean</th>\n      <th>Bwd Pkt Len Std</th>\n      <th>Flow Byts/s</th>\n      <th>Flow Pkts/s</th>\n      <th>Flow IAT Mean</th>\n      <th>Flow IAT Std</th>\n      <th>Flow IAT Max</th>\n      <th>Flow IAT Min</th>\n      <th>Fwd IAT Tot</th>\n      <th>Fwd IAT Mean</th>\n      <th>Fwd IAT Std</th>\n      <th>Fwd IAT Max</th>\n      <th>Fwd IAT Min</th>\n      <th>Bwd IAT Tot</th>\n      <th>Bwd IAT Mean</th>\n      <th>Bwd IAT Std</th>\n      <th>Bwd IAT Max</th>\n      <th>Bwd IAT Min</th>\n      <th>Fwd PSH Flags</th>\n      <th>Bwd PSH Flags</th>\n      <th>Fwd URG Flags</th>\n      <th>Bwd URG Flags</th>\n      <th>Fwd Header Len</th>\n      <th>Bwd Header Len</th>\n      <th>Fwd Pkts/s</th>\n      <th>Bwd Pkts/s</th>\n      <th>Pkt Len Min</th>\n      <th>Pkt Len Max</th>\n      <th>Pkt Len Mean</th>\n      <th>Pkt Len Std</th>\n      <th>Pkt Len Var</th>\n      <th>FIN Flag Cnt</th>\n      <th>SYN Flag Cnt</th>\n      <th>RST Flag Cnt</th>\n      <th>PSH Flag Cnt</th>\n      <th>ACK Flag Cnt</th>\n      <th>URG Flag Cnt</th>\n      <th>CWE Flag Count</th>\n      <th>ECE Flag Cnt</th>\n      <th>Down/Up Ratio</th>\n      <th>Pkt Size Avg</th>\n      <th>Fwd Seg Size Avg</th>\n      <th>Bwd Seg Size Avg</th>\n      <th>Fwd Byts/b Avg</th>\n      <th>Fwd Pkts/b Avg</th>\n      <th>Fwd Blk Rate Avg</th>\n      <th>Bwd Byts/b Avg</th>\n      <th>Bwd Pkts/b Avg</th>\n      <th>Bwd Blk Rate Avg</th>\n      <th>Subflow Fwd Pkts</th>\n      <th>Subflow Fwd Byts</th>\n      <th>Subflow Bwd Pkts</th>\n      <th>Subflow Bwd Byts</th>\n      <th>Init Fwd Win Byts</th>\n      <th>Init Bwd Win Byts</th>\n      <th>Fwd Act Data Pkts</th>\n      <th>Fwd Seg Size Min</th>\n      <th>Active Mean</th>\n      <th>Active Std</th>\n      <th>Active Max</th>\n      <th>Active Min</th>\n      <th>Idle Mean</th>\n      <th>Idle Std</th>\n      <th>Idle Max</th>\n      <th>Idle Min</th>\n      <th>Label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>80</td>\n      <td>6</td>\n      <td>37953</td>\n      <td>5</td>\n      <td>3</td>\n      <td>135</td>\n      <td>127</td>\n      <td>135</td>\n      <td>0</td>\n      <td>27</td>\n      <td>60</td>\n      <td>127</td>\n      <td>0</td>\n      <td>42</td>\n      <td>73</td>\n      <td>6903</td>\n      <td>210</td>\n      <td>5421</td>\n      <td>5403</td>\n      <td>12099</td>\n      <td>23</td>\n      <td>37953</td>\n      <td>9488</td>\n      <td>3245</td>\n      <td>12382</td>\n      <td>6013</td>\n      <td>19960</td>\n      <td>9980</td>\n      <td>13546</td>\n      <td>19559</td>\n      <td>401</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>168</td>\n      <td>104</td>\n      <td>131</td>\n      <td>79</td>\n      <td>0</td>\n      <td>135</td>\n      <td>29</td>\n      <td>57</td>\n      <td>3340</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>32</td>\n      <td>27</td>\n      <td>42</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>5</td>\n      <td>135</td>\n      <td>3</td>\n      <td>127</td>\n      <td>29200</td>\n      <td>219</td>\n      <td>1</td>\n      <td>32</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>500</td>\n      <td>17</td>\n      <td>117573474</td>\n      <td>3</td>\n      <td>0</td>\n      <td>1500</td>\n      <td>0</td>\n      <td>500</td>\n      <td>500</td>\n      <td>500</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>12</td>\n      <td>0</td>\n      <td>58800000</td>\n      <td>23800000</td>\n      <td>75600000</td>\n      <td>42000000</td>\n      <td>118000000</td>\n      <td>58800000</td>\n      <td>23800000</td>\n      <td>75600000</td>\n      <td>42000000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>24</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>500</td>\n      <td>500</td>\n      <td>500</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>666</td>\n      <td>500</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>1500</td>\n      <td>0</td>\n      <td>0</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>2</td>\n      <td>8</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>58800000</td>\n      <td>23800000</td>\n      <td>75600000</td>\n      <td>42000000</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>500</td>\n      <td>17</td>\n      <td>117573474</td>\n      <td>3</td>\n      <td>0</td>\n      <td>1500</td>\n      <td>0</td>\n      <td>500</td>\n      <td>500</td>\n      <td>500</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>12</td>\n      <td>0</td>\n      <td>58800000</td>\n      <td>23800000</td>\n      <td>75600000</td>\n      <td>42000000</td>\n      <td>118000000</td>\n      <td>58800000</td>\n      <td>23800000</td>\n      <td>75600000</td>\n      <td>42000000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>24</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>500</td>\n      <td>500</td>\n      <td>500</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>666</td>\n      <td>500</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>1500</td>\n      <td>0</td>\n      <td>0</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>2</td>\n      <td>8</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>58800000</td>\n      <td>23800000</td>\n      <td>75600000</td>\n      <td>42000000</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>500</td>\n      <td>17</td>\n      <td>99743998</td>\n      <td>5</td>\n      <td>0</td>\n      <td>2500</td>\n      <td>0</td>\n      <td>500</td>\n      <td>500</td>\n      <td>500</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>25</td>\n      <td>0</td>\n      <td>24900000</td>\n      <td>34000000</td>\n      <td>75600000</td>\n      <td>4000290</td>\n      <td>99700000</td>\n      <td>24900000</td>\n      <td>34000000</td>\n      <td>75600000</td>\n      <td>4000290</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>40</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>500</td>\n      <td>500</td>\n      <td>500</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>600</td>\n      <td>500</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>5</td>\n      <td>2500</td>\n      <td>0</td>\n      <td>0</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>4</td>\n      <td>8</td>\n      <td>4000290</td>\n      <td>0</td>\n      <td>4000290</td>\n      <td>4000290</td>\n      <td>31900000</td>\n      <td>37900000</td>\n      <td>75600000</td>\n      <td>7200397</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>500</td>\n      <td>17</td>\n      <td>99743999</td>\n      <td>5</td>\n      <td>0</td>\n      <td>2500</td>\n      <td>0</td>\n      <td>500</td>\n      <td>500</td>\n      <td>500</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>25</td>\n      <td>0</td>\n      <td>24900000</td>\n      <td>34000000</td>\n      <td>75600000</td>\n      <td>4000286</td>\n      <td>99700000</td>\n      <td>24900000</td>\n      <td>34000000</td>\n      <td>75600000</td>\n      <td>4000286</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>40</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>500</td>\n      <td>500</td>\n      <td>500</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>600</td>\n      <td>500</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>5</td>\n      <td>2500</td>\n      <td>0</td>\n      <td>0</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>4</td>\n      <td>8</td>\n      <td>4000286</td>\n      <td>0</td>\n      <td>4000286</td>\n      <td>4000286</td>\n      <td>31900000</td>\n      <td>37900000</td>\n      <td>75600000</td>\n      <td>7200399</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1048570</th>\n      <td>55484</td>\n      <td>6</td>\n      <td>1252</td>\n      <td>5</td>\n      <td>2</td>\n      <td>935</td>\n      <td>274</td>\n      <td>935</td>\n      <td>0</td>\n      <td>187</td>\n      <td>418</td>\n      <td>274</td>\n      <td>0</td>\n      <td>137</td>\n      <td>193</td>\n      <td>965654</td>\n      <td>5591</td>\n      <td>208</td>\n      <td>248</td>\n      <td>628</td>\n      <td>7</td>\n      <td>1252</td>\n      <td>313</td>\n      <td>455</td>\n      <td>978</td>\n      <td>7</td>\n      <td>628</td>\n      <td>628</td>\n      <td>0</td>\n      <td>628</td>\n      <td>628</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>124</td>\n      <td>40</td>\n      <td>3993</td>\n      <td>1597</td>\n      <td>0</td>\n      <td>935</td>\n      <td>151</td>\n      <td>330</td>\n      <td>109512</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>172</td>\n      <td>187</td>\n      <td>137</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>5</td>\n      <td>935</td>\n      <td>2</td>\n      <td>274</td>\n      <td>65535</td>\n      <td>32768</td>\n      <td>1</td>\n      <td>20</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1048571</th>\n      <td>57624</td>\n      <td>6</td>\n      <td>19055</td>\n      <td>5</td>\n      <td>2</td>\n      <td>935</td>\n      <td>341</td>\n      <td>935</td>\n      <td>0</td>\n      <td>187</td>\n      <td>418</td>\n      <td>341</td>\n      <td>0</td>\n      <td>170</td>\n      <td>241</td>\n      <td>66964</td>\n      <td>367</td>\n      <td>3175</td>\n      <td>7422</td>\n      <td>18322</td>\n      <td>3</td>\n      <td>19055</td>\n      <td>4763</td>\n      <td>9221</td>\n      <td>18593</td>\n      <td>3</td>\n      <td>18322</td>\n      <td>18322</td>\n      <td>0</td>\n      <td>18322</td>\n      <td>18322</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>124</td>\n      <td>40</td>\n      <td>262</td>\n      <td>104</td>\n      <td>0</td>\n      <td>935</td>\n      <td>159</td>\n      <td>335</td>\n      <td>112426</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>182</td>\n      <td>187</td>\n      <td>170</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>5</td>\n      <td>935</td>\n      <td>2</td>\n      <td>341</td>\n      <td>65535</td>\n      <td>32768</td>\n      <td>1</td>\n      <td>20</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1048572</th>\n      <td>57623</td>\n      <td>6</td>\n      <td>36677</td>\n      <td>5</td>\n      <td>2</td>\n      <td>935</td>\n      <td>341</td>\n      <td>935</td>\n      <td>0</td>\n      <td>187</td>\n      <td>418</td>\n      <td>341</td>\n      <td>0</td>\n      <td>170</td>\n      <td>241</td>\n      <td>34790</td>\n      <td>190</td>\n      <td>6112</td>\n      <td>14317</td>\n      <td>35332</td>\n      <td>4</td>\n      <td>36677</td>\n      <td>9169</td>\n      <td>17875</td>\n      <td>35978</td>\n      <td>7</td>\n      <td>35332</td>\n      <td>35332</td>\n      <td>0</td>\n      <td>35332</td>\n      <td>35332</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>124</td>\n      <td>40</td>\n      <td>136</td>\n      <td>54</td>\n      <td>0</td>\n      <td>935</td>\n      <td>159</td>\n      <td>335</td>\n      <td>112426</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>182</td>\n      <td>187</td>\n      <td>170</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>5</td>\n      <td>935</td>\n      <td>2</td>\n      <td>341</td>\n      <td>65535</td>\n      <td>32768</td>\n      <td>1</td>\n      <td>20</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1048573</th>\n      <td>57625</td>\n      <td>6</td>\n      <td>1849</td>\n      <td>5</td>\n      <td>2</td>\n      <td>935</td>\n      <td>341</td>\n      <td>935</td>\n      <td>0</td>\n      <td>187</td>\n      <td>418</td>\n      <td>341</td>\n      <td>0</td>\n      <td>170</td>\n      <td>241</td>\n      <td>690102</td>\n      <td>3785</td>\n      <td>308</td>\n      <td>381</td>\n      <td>895</td>\n      <td>2</td>\n      <td>1849</td>\n      <td>462</td>\n      <td>560</td>\n      <td>1171</td>\n      <td>2</td>\n      <td>895</td>\n      <td>895</td>\n      <td>0</td>\n      <td>895</td>\n      <td>895</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>124</td>\n      <td>40</td>\n      <td>2704</td>\n      <td>1081</td>\n      <td>0</td>\n      <td>935</td>\n      <td>159</td>\n      <td>335</td>\n      <td>112426</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>182</td>\n      <td>187</td>\n      <td>170</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>5</td>\n      <td>935</td>\n      <td>2</td>\n      <td>341</td>\n      <td>65535</td>\n      <td>32768</td>\n      <td>1</td>\n      <td>20</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1048574</th>\n      <td>58120</td>\n      <td>6</td>\n      <td>20580</td>\n      <td>5</td>\n      <td>2</td>\n      <td>935</td>\n      <td>299</td>\n      <td>935</td>\n      <td>0</td>\n      <td>187</td>\n      <td>418</td>\n      <td>299</td>\n      <td>0</td>\n      <td>149</td>\n      <td>211</td>\n      <td>59961</td>\n      <td>340</td>\n      <td>3430</td>\n      <td>8143</td>\n      <td>20052</td>\n      <td>6</td>\n      <td>20580</td>\n      <td>5145</td>\n      <td>10147</td>\n      <td>20365</td>\n      <td>6</td>\n      <td>20052</td>\n      <td>20052</td>\n      <td>0</td>\n      <td>20052</td>\n      <td>20052</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>124</td>\n      <td>40</td>\n      <td>242</td>\n      <td>97</td>\n      <td>0</td>\n      <td>935</td>\n      <td>154</td>\n      <td>332</td>\n      <td>110468</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>176</td>\n      <td>187</td>\n      <td>149</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>5</td>\n      <td>935</td>\n      <td>2</td>\n      <td>299</td>\n      <td>65535</td>\n      <td>32768</td>\n      <td>1</td>\n      <td>20</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>1048575 rows × 79 columns</p>\n</div>"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1670604427264,
     "user": {
      "displayName": "Fernando José Rendón Segador",
      "userId": "09288482551460164544"
     },
     "user_tz": -60
    },
    "id": "9s_HaYjkzuKk",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y = df.pop('Label')\n",
    "X = df\n",
    "\n",
    "normalizer_scaler = preprocessing.Normalizer()\n",
    "x_scaled = normalizer_scaler.fit_transform(X)\n",
    "X = pd.DataFrame(x_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1670604427264,
     "user": {
      "displayName": "Fernando José Rendón Segador",
      "userId": "09288482551460164544"
     },
     "user_tz": -60
    },
    "id": "l-9LdOome2ck",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1670604427264,
     "user": {
      "displayName": "Fernando José Rendón Segador",
      "userId": "09288482551460164544"
     },
     "user_tz": -60
    },
    "id": "FC6lXk4Az3yB",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_train = tf.convert_to_tensor(X_train)\n",
    "y_train = tf.convert_to_tensor(y_train)\n",
    "\n",
    "X_test = tf.convert_to_tensor(X_test)\n",
    "y_test = tf.convert_to_tensor(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "executionInfo": {
     "elapsed": 333,
     "status": "ok",
     "timestamp": 1670604427594,
     "user": {
      "displayName": "Fernando José Rendón Segador",
      "userId": "09288482551460164544"
     },
     "user_tz": -60
    },
    "id": "SP8ckOayytne",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "input = tf.keras.layers.Input((features,), name='feature')\n",
    "\n",
    "n1 = tf.keras.layers.Dense(16)(input)\n",
    "n1 = tf.keras.layers.Dropout(0.25)(n1)\n",
    "n1 = tf.keras.layers.Dense(32)(n1)\n",
    "n1 = tf.keras.layers.Dropout(0.25)(n1)\n",
    "n1 = tf.keras.layers.Dense(64)(n1)\n",
    "n1 = tf.keras.layers.Dropout(0.25)(n1)\n",
    "n1 = tf.keras.layers.Dense(128)(n1)\n",
    "n1 = tf.keras.layers.Dropout(0.25)(n1)\n",
    "n1 = tf.keras.layers.Dense(256)(n1)\n",
    "\n",
    "n1 = tf.keras.layers.MultiHeadAttention(num_heads=int(256/8), key_dim=256, value_dim=256, attention_axes=1)(n1, n1, n1)\n",
    "\n",
    "n1 = tf.keras.layers.Dense(256)(n1)\n",
    "n1 = tf.keras.layers.Dropout(0.25)(n1)\n",
    "n1 = tf.keras.layers.Dense(128)(n1)\n",
    "n1 = tf.keras.layers.Dropout(0.25)(n1)\n",
    "n1 = tf.keras.layers.Dense(64)(n1)\n",
    "n1 = tf.keras.layers.Dropout(0.25)(n1)\n",
    "n1 = tf.keras.layers.Dense(32)(n1)\n",
    "n1 = tf.keras.layers.Dropout(0.25)(n1)\n",
    "n1 = tf.keras.layers.Dense(16)(n1)\n",
    "\n",
    "output = tf.keras.layers.Dense(classes, activation='softmax')(n1)\n",
    "\n",
    "model = tf.keras.Model(inputs=input, outputs=output)\n",
    "\n",
    "adv_config = nsl.configs.make_adv_reg_config(multiplier=0.2, adv_step_size=0.05)\n",
    "adv_model = nsl.keras.AdversarialRegularization(model, adv_config=adv_config)\n",
    "\n",
    "# Compile, train, and evaluate.\n",
    "adv_model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 269,
     "status": "ok",
     "timestamp": 1670604427855,
     "user": {
      "displayName": "Fernando José Rendón Segador",
      "userId": "09288482551460164544"
     },
     "user_tz": -60
    },
    "id": "-EUxz4vRy7YP",
    "outputId": "1c8c1a81-6e6b-4129-f8a2-9d22f904cb87",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " feature (InputLayer)           [(None, 78)]         0           []                               \n",
      "                                                                                                  \n",
      " dense_11 (Dense)               (None, 16)           1264        ['feature[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_8 (Dropout)            (None, 16)           0           ['dense_11[0][0]']               \n",
      "                                                                                                  \n",
      " dense_12 (Dense)               (None, 32)           544         ['dropout_8[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_9 (Dropout)            (None, 32)           0           ['dense_12[0][0]']               \n",
      "                                                                                                  \n",
      " dense_13 (Dense)               (None, 64)           2112        ['dropout_9[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_10 (Dropout)           (None, 64)           0           ['dense_13[0][0]']               \n",
      "                                                                                                  \n",
      " dense_14 (Dense)               (None, 128)          8320        ['dropout_10[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_11 (Dropout)           (None, 128)          0           ['dense_14[0][0]']               \n",
      "                                                                                                  \n",
      " dense_15 (Dense)               (None, 256)          33024       ['dropout_11[0][0]']             \n",
      "                                                                                                  \n",
      " multi_head_attention_1 (MultiH  (None, 256)         8413440     ['dense_15[0][0]',               \n",
      " eadAttention)                                                    'dense_15[0][0]',               \n",
      "                                                                  'dense_15[0][0]']               \n",
      "                                                                                                  \n",
      " dense_16 (Dense)               (None, 256)          65792       ['multi_head_attention_1[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_12 (Dropout)           (None, 256)          0           ['dense_16[0][0]']               \n",
      "                                                                                                  \n",
      " dense_17 (Dense)               (None, 128)          32896       ['dropout_12[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_13 (Dropout)           (None, 128)          0           ['dense_17[0][0]']               \n",
      "                                                                                                  \n",
      " dense_18 (Dense)               (None, 64)           8256        ['dropout_13[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_14 (Dropout)           (None, 64)           0           ['dense_18[0][0]']               \n",
      "                                                                                                  \n",
      " dense_19 (Dense)               (None, 32)           2080        ['dropout_14[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_15 (Dropout)           (None, 32)           0           ['dense_19[0][0]']               \n",
      "                                                                                                  \n",
      " dense_20 (Dense)               (None, 16)           528         ['dropout_15[0][0]']             \n",
      "                                                                                                  \n",
      " dense_21 (Dense)               (None, 3)            51          ['dense_20[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 8,568,307\n",
      "Trainable params: 8,568,307\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 48
    },
    "executionInfo": {
     "elapsed": 447,
     "status": "ok",
     "timestamp": 1670604428298,
     "user": {
      "displayName": "Fernando José Rendón Segador",
      "userId": "09288482551460164544"
     },
     "user_tz": -60
    },
    "id": "844W7YPn82Gw",
    "outputId": "ea88bcec-2ee8-4229-e43f-6c1a767fdc89",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(model, \n",
    "                          show_shapes=True,\n",
    "                          show_dtype=True,\n",
    "                          show_layer_names=True,\n",
    "                          rankdir='LR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RjM9Xf2Ry-lq",
    "outputId": "3f4f80c6-a5ac-4e5e-8981-be5081cd7e3c",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1639/1639 [==============================] - 641s 389ms/step - loss: 0.1268 - sparse_categorical_crossentropy: 0.0743 - sparse_categorical_accuracy: 0.9886 - scaled_adversarial_loss: 0.0525 - val_loss: 0.0536 - val_sparse_categorical_crossentropy: 0.0070 - val_sparse_categorical_accuracy: 0.9997 - val_scaled_adversarial_loss: 0.0466\n",
      "Epoch 2/10\n",
      "1639/1639 [==============================] - 614s 375ms/step - loss: 0.0475 - sparse_categorical_crossentropy: 0.0116 - sparse_categorical_accuracy: 0.9979 - scaled_adversarial_loss: 0.0359 - val_loss: 0.0386 - val_sparse_categorical_crossentropy: 0.0055 - val_sparse_categorical_accuracy: 0.9997 - val_scaled_adversarial_loss: 0.0331\n",
      "Epoch 3/10\n",
      "1639/1639 [==============================] - 603s 368ms/step - loss: 0.0232 - sparse_categorical_crossentropy: 0.0048 - sparse_categorical_accuracy: 0.9993 - scaled_adversarial_loss: 0.0184 - val_loss: 0.0058 - val_sparse_categorical_crossentropy: 5.1237e-04 - val_sparse_categorical_accuracy: 0.9999 - val_scaled_adversarial_loss: 0.0053\n",
      "Epoch 4/10\n",
      "1639/1639 [==============================] - 596s 364ms/step - loss: 0.7719 - sparse_categorical_crossentropy: 0.4965 - sparse_categorical_accuracy: 0.9907 - scaled_adversarial_loss: 0.2754 - val_loss: 0.0581 - val_sparse_categorical_crossentropy: 0.0195 - val_sparse_categorical_accuracy: 0.9974 - val_scaled_adversarial_loss: 0.0386\n",
      "Epoch 5/10\n",
      "1639/1639 [==============================] - 587s 358ms/step - loss: 0.0677 - sparse_categorical_crossentropy: 0.0297 - sparse_categorical_accuracy: 0.9877 - scaled_adversarial_loss: 0.0380 - val_loss: 0.0494 - val_sparse_categorical_crossentropy: 0.0160 - val_sparse_categorical_accuracy: 0.9950 - val_scaled_adversarial_loss: 0.0334\n",
      "Epoch 6/10\n",
      "1639/1639 [==============================] - 608s 371ms/step - loss: 0.0547 - sparse_categorical_crossentropy: 0.0209 - sparse_categorical_accuracy: 0.9922 - scaled_adversarial_loss: 0.0338 - val_loss: 0.0313 - val_sparse_categorical_crossentropy: 0.0051 - val_sparse_categorical_accuracy: 0.9996 - val_scaled_adversarial_loss: 0.0263\n",
      "Epoch 7/10\n",
      "1639/1639 [==============================] - 608s 371ms/step - loss: 0.0394 - sparse_categorical_crossentropy: 0.0134 - sparse_categorical_accuracy: 0.9966 - scaled_adversarial_loss: 0.0260 - val_loss: 0.0215 - val_sparse_categorical_crossentropy: 0.0029 - val_sparse_categorical_accuracy: 0.9996 - val_scaled_adversarial_loss: 0.0186\n",
      "Epoch 8/10\n",
      "1639/1639 [==============================] - 600s 366ms/step - loss: 0.0316 - sparse_categorical_crossentropy: 0.0101 - sparse_categorical_accuracy: 0.9980 - scaled_adversarial_loss: 0.0215 - val_loss: 0.0136 - val_sparse_categorical_crossentropy: 0.0017 - val_sparse_categorical_accuracy: 0.9997 - val_scaled_adversarial_loss: 0.0119\n",
      "Epoch 9/10\n",
      "1639/1639 [==============================] - 604s 369ms/step - loss: 0.0262 - sparse_categorical_crossentropy: 0.0078 - sparse_categorical_accuracy: 0.9988 - scaled_adversarial_loss: 0.0184 - val_loss: 0.0046 - val_sparse_categorical_crossentropy: 4.6249e-04 - val_sparse_categorical_accuracy: 0.9999 - val_scaled_adversarial_loss: 0.0042\n",
      "Epoch 10/10\n",
      "1639/1639 [==============================] - 626s 382ms/step - loss: 0.0199 - sparse_categorical_crossentropy: 0.0044 - sparse_categorical_accuracy: 0.9993 - scaled_adversarial_loss: 0.0155 - val_loss: 0.0046 - val_sparse_categorical_crossentropy: 3.9286e-04 - val_sparse_categorical_accuracy: 0.9999 - val_scaled_adversarial_loss: 0.0042\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x1ab9af39190>"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adv_model.fit({'feature': X_train, 'label': y_train}, epochs=10, batch_size=512, validation_data={'feature': X_test, 'label': y_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "Pmt7mlJoQ-Np",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "209715/209715 [==============================] - 1474s 7ms/step - loss: 0.0051 - sparse_categorical_crossentropy: 3.9319e-04 - sparse_categorical_accuracy: 0.9999 - scaled_adversarial_loss: 0.0047\n"
     ]
    },
    {
     "data": {
      "text/plain": "[0.005064707715064287,\n 0.0003931857645511627,\n 0.9998950958251953,\n 0.00467142928391695]"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adv_model.evaluate({'feature':X_test, 'label':y_test}, batch_size=1)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "mount_file_id": "1l_2YpamsRqa2kvQbF6VcRh1L-ZVNw2LN",
   "authorship_tag": "ABX9TyOZ6tqQxYPy3g7WnP4d6Wrs"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}